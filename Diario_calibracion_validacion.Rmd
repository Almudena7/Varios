---
title: "Diario_calibracion_validacion"
output: html_document
---

```{r}
setwd("C:/DELL/GDrive_2/Instar/calibracion_validacion/fuentes_datos_validacion/COPLAS_PLAGAS/")
```

# Agregación de datos INSTAR: 

Entiendo que agregais los datos de NetLogo para poder hacer la regresión COPLAS vs INSTAR, ¿es correcto? Sin embargo, sumar los datos de huevos, l1, l2 y crisalidas de todos los días no parece adecuado, ¿así habrá individuos que se cuentan dos veces no? Entiendo que es difícil encontrar el parámetro adecuado, ya que no sabemos qué huevos hoy son los mismos que mañana y cuáles son nuevos... Antonio me comenta que ahí podría entrar un análisis de dinámica poblacional. Ya que la cosa se complica bastante, quizás para simplificar se podría probar con la media, el máximo y/o el mínimo, que quizás sean valores más reales que el acumulado que se ha usado hasta ahora.

De hecho, "Resultados_agreg_Instar_SN.csv" tiene más individuos en L2 que en L1, lo cual no tiene sentido...

## Datos INSTAR crudos:
   
```{r}
# Datos crudos de INSTAR_SN:
huevos <-read.table("huevos_sn.csv", header=T, sep=",", dec=".")
L1 <-read.table("L1_sn.csv", header=T, sep=",", dec=".")
L2 <-read.table("L2_sn.csv", header=T, sep=",", dec=".")
crisalidas <-read.table("crisalidas_sn.csv", header=T, sep=",", dec=".")
exergia <-read.table("vigor_sn.csv", header=T, sep=",", dec=".")

# Juntamos todos en una misma tabla

INSTAR_SN <- cbind(huevos, L1$L1, L2$L2, crisalidas$crisalida, exergia$exergia)
names(INSTAR_SN)[1] <- "fecha"
names(INSTAR_SN)[3] <- "l1"
names(INSTAR_SN)[4] <- "l2"
names(INSTAR_SN)[5] <- "crisalidas"
names(INSTAR_SN)[6] <- "exergia"

# Crear columna anio
INSTAR_SN$fecha <-as.Date(INSTAR_SN$fecha, format="%d-%m-%y") 
INSTAR_SN$anio<-as.numeric(format(INSTAR_SN$fecha, "%Y"))
```

**Importante**: recordar que mientras huevos, l1, l2 y crisalidas son valores absolutos (número total de individuos en el mundo Netlogo), exergia es la media del vigor de todos los hospedadores del mundo NetLogo.

## Agregación por máximo
```{r}
max_huevos <- aggregate(x = INSTAR_SN$huevos, by=list(anio=INSTAR_SN$anio), FUN=max, na.rm=TRUE)
names(max_huevos)[2] <- "max_huevos"
max_l1 <- aggregate(x = INSTAR_SN$l1, by=list(anio=INSTAR_SN$anio), FUN=max, na.rm=TRUE)
names(max_l1)[2] <- "max_l1"
max_l2 <- aggregate(x = INSTAR_SN$l2, by=list(anio=INSTAR_SN$anio), FUN=max, na.rm=TRUE)
names(max_l2)[2] <- "max_l2"
max_crisalidas <- aggregate(x = INSTAR_SN$crisalidas, by=list(anio=INSTAR_SN$anio), FUN=max, na.rm=TRUE)
names(max_crisalidas)[2] <- "max_crisalidas"
max_exergia <- aggregate(x = INSTAR_SN$exergia, by=list(anio=INSTAR_SN$anio), FUN=max, na.rm=TRUE)
names(max_exergia)[2] <- "max_exergia"

max_INSTAR <- cbind(max_huevos,max_l1, max_l2, max_crisalidas, max_exergia)
max_INSTAR <- max_INSTAR[ -c(3,5,7,9) ]
```

## Agregación por mínimo
```{r}
min_huevos <- aggregate(x = INSTAR_SN$huevos, by=list(anio=INSTAR_SN$anio), FUN=min, na.rm=TRUE)
names(min_huevos)[2] <- "min_huevos"
min_l1 <- aggregate(x = INSTAR_SN$l1, by=list(anio=INSTAR_SN$anio), FUN=min, na.rm=TRUE)
names(min_l1)[2] <- "min_l1"
min_l2 <- aggregate(x = INSTAR_SN$l2, by=list(anio=INSTAR_SN$anio), FUN=min, na.rm=TRUE)
names(min_l2)[2] <- "min_l2"
min_crisalidas <- aggregate(x = INSTAR_SN$crisalidas, by=list(anio=INSTAR_SN$anio), FUN=min, na.rm=TRUE)
names(min_crisalidas)[2] <- "min_crisalidas"
min_exergia <- aggregate(x = INSTAR_SN$exergia, by=list(anio=INSTAR_SN$anio), FUN=min, na.rm=TRUE)
names(min_exergia)[2] <- "min_exergia"

min_INSTAR <- cbind(min_huevos,min_l1, min_l2, min_crisalidas, min_exergia)
min_INSTAR <- min_INSTAR[ -c(3,5,7,9) ]
```

## Agregación por media
```{r}
mean_huevos <- aggregate(x = INSTAR_SN$huevos, by=list(anio=INSTAR_SN$anio), FUN=mean, na.rm=TRUE)
names(mean_huevos)[2] <- "mean_huevos"
mean_l1 <- aggregate(x = INSTAR_SN$l1, by=list(anio=INSTAR_SN$anio), FUN=mean, na.rm=TRUE)
names(mean_l1)[2] <- "mean_l1"
mean_l2 <- aggregate(x = INSTAR_SN$l2, by=list(anio=INSTAR_SN$anio), FUN=mean, na.rm=TRUE)
names(mean_l2)[2] <- "mean_l2"
mean_crisalidas <- aggregate(x = INSTAR_SN$crisalidas, by=list(anio=INSTAR_SN$anio), FUN=mean, na.rm=TRUE)
names(mean_crisalidas)[2] <- "mean_crisalidas"
mean_exergia <- aggregate(x = INSTAR_SN$exergia, by=list(anio=INSTAR_SN$anio), FUN=mean, na.rm=TRUE)
names(mean_exergia)[2] <- "mean_exergia"

mean_INSTAR <- cbind(mean_huevos, mean_l1, mean_l2, mean_crisalidas, mean_exergia)
mean_INSTAR <- mean_INSTAR[ -c(3,5,7,9) ]
```

## Exportación e importación de datos de agregación por máximo, mínimo y media
```{r}
# write.csv(max_INSTAR, "max_INSTAR.csv", row.names=FALSE, na="")
# write.csv(min_INSTAR, "min_INSTAR.csv", row.names=FALSE, na="")
# write.csv(mean_INSTAR, "mean_INSTAR.csv", row.names=FALSE, na="")

max_INSTAR<-read.table("max_INSTAR.csv", header=T, sep=",", dec=".")
min_INSTAR<-read.table("min_INSTAR.csv", header=T, sep=",", dec=".")
mean_INSTAR<-read.table("mean_INSTAR.csv", header=T, sep=",", dec=".")
```

Sigue sin convencerme esta agregación:

- máximos: dos años con el mismo número de individuos pueden tener máximos muy diferentes, según la puesta, eclosión, etc coincida más o menos en el tiempo (mismo efecto que la media)
- mínimos: claramente subestima la población, al menos en huevos, l1, l2 y crisálidas, ya que debido a la estacionalidad de cada fase se dan días con valores 0, y por tanto el mínimo es 0, no siendo este valor representativo de la población ese año. 
- medias: para dos años con el mismo número total de inviduos, en un año con el instar que sea (huevos, l1, l2 o crisalidas) muy repartidos a lo largo del tiempo, la media saldrá menor que la de un año con el mismo número de individuos pero concentrados en un período más corto de tiempo.

Probablemente haya alguna opción mejor, pero no sé cuál. 

# Regresión: 

Por lo que veo habéis calculado una regresión lineal entre COPLAS e INSTAR, ¿por qué esperáis una relación lineal entre ambas variables? Lo ideal sería buscar la función que explica dicha relación, y ver qué tipo de función (lineal, logarítmica...) es, ¿no? En cualquier caso, quizás lo más esperable es una función logarítmica, como hace Cayuela (hace un glm, pero sobre datos en base logarítmica!). Intuitivamente, yo esperaría que para percibir cierta defoliación es necesario un número mínimo de individuos, por debajo del cual no se observa defoliación y a partir de cierta cantidad de individuos la defoliación es máxima, dando igual si ese valor se sobrepasa por mucho o por poco (si todos los árboles están defoliados da igual que haya X que X·10 individuos, por lo que ya no hay relación lineal), por lo que yo esperaría una relación exponencial.

Me preocupa que hay muchos datos 0 de COPLAS con valores muuuy diferentes de NetLogo... La agregación juega un papel importante ahí, quizás al usar otra agregación sale algo mejor (esperemos).

## Transformación log de datos INSTAR

**DUDA* Es e la base correcta?

```{r}

# Transformación log de los máximos
log_max_INSTAR<- data.frame("anio" = max_INSTAR$anio, log_max_huevos = (log(max_INSTAR$max_huevos)), log_max_l1 = (log(max_INSTAR$max_l1)), log_max_l2 = (log(max_INSTAR$max_l2)), log_max_crisalidas = (log(max_INSTAR$max_crisalidas)), log_max_exergia = (log(max_INSTAR$max_exergia)))

# Transformación log de los mínimos
log_min_INSTAR<- data.frame("anio" = min_INSTAR$anio, log_min_huevos = (log(min_INSTAR$min_huevos)), log_min_l1 = (log(min_INSTAR$min_l1)), log_min_l2 = (log(min_INSTAR$min_l2)), log_min_crisalidas = (log(min_INSTAR$min_crisalidas)), log_min_exergia = (log(min_INSTAR$min_exergia)))

# Transformación log de las medias
log_mean_INSTAR<- data.frame("anio" = mean_INSTAR$anio, log_mean_huevos = (log(mean_INSTAR$mean_huevos)), log_mean_l1 = (log(mean_INSTAR$mean_l1)), log_mean_l2 = (log(mean_INSTAR$mean_l2)), log_mean_crisalidas = (log(mean_INSTAR$mean_crisalidas)), log_mean_exergia = (log(mean_INSTAR$mean_exergia)))
```

## Importación de datos de COPLAS y exploración preliminar
```{r}
COPLAS_SN_completo<-read.csv("cortijuela.csv", header=TRUE, dec =".", sep=",") # Sin agregar, datos brutos

boxplot(COPLAS_SN_completo$GRADO.REVISADO ~ COPLAS_SN_completo$RODAL)
plot(COPLAS_SN_completo$GRADO.REVISADO ~ COPLAS_SN_completo$fecha)

COPLAS_SN<-read.csv("coplas_cortijuela_prueba.csv", header=TRUE, dec =".", sep=",") # Medias para cada rodal (agregado)
```

COPLAS es una variable discreta:

- ¿Es correcto hacer la media (al menos tal y como está hecha) en una variable discreta?
- En caso de que sea correcto, ¿se debe/hay forma de considerar la varianza en la regresión?
- ¿Debe considerarse COPLAS de alguna manera especial en la regresión por ser una variable discreta?

## Correlaciones y regresiones

- ¿Se cumplen las asunciones de una regresión? (normalidad,...)
- ¿lm o glm? ¿cor y/o lm/glm?

```{r}
# pruebas
cor(COPLAS_SN_subset$INFE_AVG_ROUND, log_max_INSTAR$log_max_l1)
cor.test(COPLAS_SN_subset$INFE_AVG_ROUND, log_max_INSTAR$log_max_l1) 
reg1<-lm(COPLAS_SN_subset$INFE_AVG_ROUND ~ log_max_INSTAR$log_max_l1)
summary(reg1)
plot(COPLAS_SN_subset$INFE_AVG_ROUND ~ log_max_INSTAR$log_max_l1)
```

# Regresión múltiple: 

No entiendo esto... Si l2 viene de l1, al hacer una regresión múltiple l1+l2 (o huevos+l1, o cualquier conbinación de variables de densidad de población), ¿no se está metiendo una redundancia? Sin embargo, sí me parece que podría ser interesante hacer una regresión múltiple considerando una variable de densidad de población y una relacionada con las condiciones climáticas (tmin, tmax y/o tmedia), ya que se podría esperar que, por ejemplo, huevos+tmin sea un buen predictor de COPLAS, ¿no?

## Datos de temperatura:
```{r}
temp_sn<-read.csv("temp_sn.csv", header=TRUE, dec =".", sep=",")
```

# Series temporales  

No sé muy bien cuál es el objetivo de el análisis de series temporales, por lo que quizás lo que digo no tiene sentido, corregidme plis :) 

*--> Cuantificar el grado de ajuste entre ambas series temporales (COPLAS e INSTAR)*

Según lo entiendo, queremos hacer un análisis de series temporales comparando COPLAS e INSTAR, ya que al ser variables que cambian en el tiempo debido a varios factores (condiciones de cada año, estacionalidad, variabilidad,...) su análisis basado en regresión es limitado. En tal caso, creo que es una pena usar datos agregados de INSTAR (perdiendo resolución) cuando precisamente el análisis como serie temporal nos mostraría la estacionalidad, la tendencia, etc. Por tanto, yo usaría los datos brutos de INSTAR. Ahora, hay un problema, y es que la función ts no se lleva bien con los años bisiestos, ya que la frecuencia tiene que ser un valor fijo para toda la serie (que no para dos series, por lo que no es un problema comparar COPLAS e INSTAR aunque tengan distinta frecuencia). En los foros proponen usar zoo para evitar este problema, que es lo que usamos en Ecoinformática, creo... Otra opción sería eliminar de los datos de INSTAR el 29 de febrero de los años bisiestos, aunque parece una solución poco elegante...

En cuanto al error que te sale en el código, entiendo que es porque cuando la frecuencia es 1, decompose no funciona ya que no se puede observar estacionalidad si hay una sola medida por año. Por eso cambiando a freq=2 se elimina el error, pero no es correcto ya que nosotros sólo tenemos una medida/año. Por tanto, yo entiendo que no se puede aplicar la función decompose sobre COPLAS, sino que habrá que buscar otras herramientas para evaluar tendencias. En cualquier caso, y después de hablar con Antonio, yo entiendo que lo que habría que hacer es coger los datos de INSTAR, analizarlos (en bruto) como serie temporal, buscando estacionalidad, tendencias, ruido, etc. y quizás comparar esta serie con una serie climática (tmin, tmax y/o tmedia), de esta manera demostrando que los resultados del modelo guardan relación con las condiciones climáticas, como se espera del código. Si además encontramos la forma de analizar series temporales de frecuencia 1 entonces podríamos comparar COPLAS e INSTAR.

```{r}
# Pruebas (basado en el reto final de ecoinformática)
## Exploratory plot
plot(INSTAR_SN$fecha, INSTAR_SN$huevos, type='o', 
      xlab='year', pch=19, col='#325B84',
      ylab='huevos', ylim=c(0,1500000))

## Trend analysis

library('Kendall') 
m <- MannKendall(INSTAR_SN$huevos)
m

# Creo que considera la serie como valores puntuales (no medidas diarias) por lo que no encuentra tendencia ya que sube y baja en cada año (tiene estacionalidad)

### Test a linear regression
ml <- lm(INSTAR_SN$fecha~INSTAR_SN$huevos)
summary(ml)

# ERROR: no sabe hacer un lm sobre una fecha

huevos_zoo <- zoo(INSTAR_SN$fecha~INSTAR_SN$huevos)

#Definimos la tabla como serie temporal - cada fila es una serie
str(huevos_zoo)
View(huevos_zoo)

huevos_theil <- mannKen(as.ts(huevos_zoo)) #Ejecutamos el test
View(nieve_theil)
nieve_theil<-as.data.frame(nieve_theil)
```
